{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c134260c-b1b9-4a51-a79a-39bc08e0863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TransformerEncoder import TransformerEncoderConfig, TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d3aceb-0144-4a30-aff1-70d2d1f351e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerEncoderConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05308412-1ead-4681-9c6b-3d88326b3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerEncoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e93b13-e8b4-4596-a1ce-d60cccde1cd8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (pos_conv): Sequential(\n",
       "    (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "    (1): SamePad()\n",
       "    (2): GELU()\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (10): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): TransformerSentenceEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55fd9d0-1f4d-427d-aea8-090efdd7fcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "TransformerEncoder                                 --                        --\n",
       "├─ModuleList: 1-1                                  --                        --\n",
       "├─Sequential: 1-2                                  [1, 768, 333]             --\n",
       "│    └─Conv1d: 2-1                                 [1, 768, 334]             4,719,488\n",
       "│    └─SamePad: 2-2                                [1, 768, 333]             --\n",
       "│    └─GELU: 2-3                                   [1, 768, 333]             --\n",
       "├─FusedLayerNorm: 1-3                              [1, 333, 768]             1,536\n",
       "├─ModuleList: 1-1                                  --                        --\n",
       "│    └─TransformerSentenceEncoderLayer: 2-4        [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-1                [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-2                           [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-3                    [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-4                            [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-5                           [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-6                            [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-7                           [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-8                    [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-5        [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-9                [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-10                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-11                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-12                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-13                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-14                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-15                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-16                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-6        [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-17               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-18                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-19                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-20                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-21                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-22                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-23                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-24                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-7        [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-25               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-26                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-27                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-28                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-29                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-30                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-31                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-32                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-8        [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-33               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-34                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-35                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-36                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-37                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-38                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-39                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-40                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-9        [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-41               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-42                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-43                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-44                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-45                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-46                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-47                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-48                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-10       [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-49               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-50                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-51                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-52                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-53                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-54                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-55                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-56                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-11       [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-57               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-58                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-59                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-60                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-61                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-62                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-63                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-64                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-12       [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-65               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-66                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-67                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-68                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-69                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-70                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-71                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-72                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-13       [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-73               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-74                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-75                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-76                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-77                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-78                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-79                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-80                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-14       [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-81               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-82                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-83                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-84                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-85                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-86                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-87                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-88                   [333, 1, 768]             1,536\n",
       "│    └─TransformerSentenceEncoderLayer: 2-15       [333, 1, 768]             --\n",
       "│    │    └─MultiheadAttention: 3-89               [333, 1, 768]             2,362,368\n",
       "│    │    └─Dropout: 3-90                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-91                   [333, 1, 768]             1,536\n",
       "│    │    └─Linear: 3-92                           [333, 1, 3072]            2,362,368\n",
       "│    │    └─Dropout: 3-93                          [333, 1, 3072]            --\n",
       "│    │    └─Linear: 3-94                           [333, 1, 768]             2,360,064\n",
       "│    │    └─Dropout: 3-95                          [333, 1, 768]             --\n",
       "│    │    └─FusedLayerNorm: 3-96                   [333, 1, 768]             1,536\n",
       "====================================================================================================\n",
       "Total params: 61,427,072\n",
       "Trainable params: 61,427,072\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 22.51\n",
       "====================================================================================================\n",
       "Input size (MB): 1.02\n",
       "Forward/backward pass size (MB): 175.96\n",
       "Params size (MB): 245.71\n",
       "Estimated Total Size (MB): 422.69\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, (1, 333, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fdc433-8b0d-42ac-8a33-49ff199ba53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
