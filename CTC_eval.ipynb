{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5e6211-5b97-44dd-a26b-eb5937fa5010",
   "metadata": {},
   "source": [
    "#### NOTE: Also need to identify how fairseq evaluates model by wer/cer on librispeech -> enables beam search decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf301ed8-fbb6-42e9-9582-ac8f4fa210b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_fsq_model import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02f652d-d939-4cfc-8aa3-090b64019439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('wav2vec_small_960h.pt')\n",
    "model = load_model('wav2vec2_vox_960h_new.pt')\n",
    "# model = load_model('wav2vec_big_960h.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1a8c34-f6bf-428d-8588-4a21ba0e5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf7e6837-96bd-4b36-9810-dbb021a14bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "test_data = torchaudio.datasets.LIBRISPEECH(\"../\", \"test-clean\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5513a44-e591-4ba6-a745-2d00f90d91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import groupby\n",
    "\n",
    "json_dict = {\"<s>\": 0, \"<pad>\": 1, \"</s>\": 2, \"<unk>\": 3, \"|\": 4, \"E\": 5, \"T\": 6, \"A\": 7, \"O\": 8, \"N\": 9, \"I\": 10, \"H\": 11, \"S\": 12, \"R\": 13, \"D\": 14, \"L\": 15, \"U\": 16, \"M\": 17, \"W\": 18, \"C\": 19, \"F\": 20, \"G\": 21, \"Y\": 22, \"P\": 23, \"B\": 24, \"V\": 25, \"K\": 26, \"'\": 27, \"X\": 28, \"J\": 29, \"Q\": 30, \"Z\": 31}\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, json_dict):\n",
    "        self.dict = json_dict\n",
    "        self.look_up = np.asarray(list(self.dict.keys()))\n",
    "\n",
    "    def decode(self, ids):\n",
    "        converted_tokens = self.look_up[ids]\n",
    "        fused_tokens = [tok[0] for tok in groupby(converted_tokens)]\n",
    "        output = ' '.join(''.join(''.join(fused_tokens).split(\"<s>\")).split(\"|\"))\n",
    "        return output\n",
    "    \n",
    "decoder = Decoder(json_dict=json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def22855-9057-404f-b1a4-f557ef3637e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44c492c-a510-4b6b-89e2-330408f5d3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afae6c760e6b4a828a533f746ceafa6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.03210590383444918\n"
     ]
    }
   ],
   "source": [
    "# Evaluation without batch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from jiwer import wer\n",
    "from datasets import load_metric\n",
    "\n",
    "wer_metric = load_metric(\"wer\")\n",
    "\n",
    "wer_ = []\n",
    "\n",
    "for i, data in enumerate(tqdm(test_data)):\n",
    "    logits = model(source=data[0].cuda(), padding_mask=None)[\"encoder_out\"].transpose(0,1)\n",
    "    predicted_ids = np.argmax(logits.cpu().detach().numpy(), axis=-1)\n",
    "    predictions = [decoder.decode(ids) for ids in predicted_ids]\n",
    "    labels = [data[2]]\n",
    "    \n",
    "    # wer_.append(wer(labels, predictions))\n",
    "    wer_metric.add_batch(predictions=predictions, references=labels)\n",
    "    \n",
    "# print(f\"WER: {np.mean(wer_)}\")\n",
    "print(f\"WER: {wer_metric.compute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdfc6e-baeb-4695-b1af-84132261b82a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47728c77-054d-4313-9249-43c031541ccf",
   "metadata": {},
   "source": [
    "## Implement batch evaluation & metric wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc481ef9-e0cd-4b25-a2c4-d8ee2bd22cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# import torch\n",
    "\n",
    "# def data_collator(features):\n",
    "#     # split inputs and labels since they have to be of different lengths and need\n",
    "#     # different padding methods\n",
    "#     input_features = [feature[0].squeeze(0) for feature in features]\n",
    "#     labels = [feature[2] for feature in features]\n",
    "\n",
    "#     src = pad_sequence(input_features, batch_first=True, padding_value=0.0)\n",
    "#     mask = torch.zeros(src.shape).masked_fill_(src==0, 1)\n",
    "\n",
    "#     return src, mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e19e80-7dd8-41bb-a8e7-d93f94be61bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]):\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [feature[0][0] for feature in features]\n",
    "        labels = [feature[2] for feature in features]\n",
    "        \n",
    "        src = pad_sequence(input_features, batch_first=True, padding_value=0)\n",
    "        mask = torch.zeros(src.shape).masked_fill_(src==0, 1)\n",
    "        \n",
    "        return {'src': src, 'mask': mask, 'labels': labels}\n",
    "    \n",
    "data_collator = DataCollatorWithPadding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e4732a-7080-4106-a81c-faf72c5e7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_dataloader = DataLoader(test_data, batch_size=2, collate_fn=data_collator, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "434bf232-be3f-4cac-bdb6-19c46808b194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ab572ec42f4082aeb6d08e667b03b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.03596137763247928\n",
      "CER: 0.012510212055553582\n"
     ]
    }
   ],
   "source": [
    "# Full batch evaluation\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "wer_ = []\n",
    "cer_ = []\n",
    "\n",
    "for i, batch in enumerate(tqdm(test_dataloader)):\n",
    "    logits = model(source=batch['src'].cuda(), padding_mask=batch['mask'])[\"encoder_out\"].transpose(0,1)\n",
    "    predicted_ids = np.argmax(logits.cpu().detach().numpy(), axis=-1)\n",
    "    predictions = [decoder.decode(ids) for ids in predicted_ids]\n",
    "    \n",
    "    # wer_.append(wer_metric.compute(predictions=predictions, references=labels))\n",
    "    # cer_.append(cer_metric.compute(predictions=predictions, references=labels))\n",
    "    wer_metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "    cer_metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "    \n",
    "wer = wer_metric.compute()\n",
    "cer = cer_metric.compute()\n",
    "\n",
    "# print(f\"WER: {np.mean(wer_)}\")\n",
    "# print(f\"CER: {np.mean(cer_)}\")\n",
    "print(f\"WER: {wer}\")\n",
    "print(f\"CER: {cer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec835ab8-742c-4e54-993a-222064d371cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
