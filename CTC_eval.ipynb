{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5e6211-5b97-44dd-a26b-eb5937fa5010",
   "metadata": {},
   "source": [
    "#### NOTE: Also need to identify how fairseq evaluates model by wer/cer on librispeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf301ed8-fbb6-42e9-9582-ac8f4fa210b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_fsq_model import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff992b9-c95c-49eb-9288-6c60eca4ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('wav2vec_small_960h.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1a8c34-f6bf-428d-8588-4a21ba0e5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf7e6837-96bd-4b36-9810-dbb021a14bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 166960])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get one audio sample from librispeech\n",
    "import torchaudio\n",
    "test_data = torchaudio.datasets.LIBRISPEECH(\"../\", \"test-clean\", download=True)\n",
    "sample = test_data[0][0]\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba9f0e9-0949-4aa2-9958-d1554122c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = {\"<s>\": 0, \"<pad>\": 1, \"</s>\": 2, \"<unk>\": 3, \"|\": 4, \"E\": 5, \"T\": 6, \"A\": 7, \"O\": 8, \"N\": 9, \"I\": 10, \"H\": 11, \"S\": 12, \"R\": 13, \"D\": 14, \"L\": 15, \"U\": 16, \"M\": 17, \"W\": 18, \"C\": 19, \"F\": 20, \"G\": 21, \"Y\": 22, \"P\": 23, \"B\": 24, \"V\": 25, \"K\": 26, \"'\": 27, \"X\": 28, \"J\": 29, \"Q\": 30, \"Z\": 31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5513a44-e591-4ba6-a745-2d00f90d91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import groupby\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, json_dict):\n",
    "        self.dict = json_dict\n",
    "        self.look_up = np.asarray(list(self.dict.keys()))\n",
    "\n",
    "    def decode(self, ids):\n",
    "        converted_tokens = self.look_up[ids]\n",
    "        fused_tokens = [tok[0] for tok in groupby(converted_tokens)]\n",
    "        output = ' '.join(''.join(''.join(fused_tokens).split(\"<s>\")).split(\"|\"))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f345161-225d-4295-8572-dcab56c42dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(json_dict=json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cabd5f5-400d-4326-861d-8f57928667fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865f3e41-195a-44af-ab1e-c50daccb70c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits = model(source=sample.cuda(), padding_mask=None)[\"encoder_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44c492c-a510-4b6b-89e2-330408f5d3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12fa1b6732f41a2868940c21cf9634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.038536101512586685\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from jiwer import wer\n",
    "\n",
    "wer_ = []\n",
    "\n",
    "for i, data in enumerate(tqdm(test_data)):\n",
    "    logits = model(source=data[0].cuda(), padding_mask=None)[\"encoder_out\"]\n",
    "    predicted_ids = torch.argmax(logits[:, 0], axis=-1)\n",
    "    predictions = decoder.decode(predicted_ids.cpu())\n",
    "    labels = data[2]\n",
    "    \n",
    "    wer_.append(wer(labels, predictions))\n",
    "    \n",
    "print(f\"WER: {np.mean(wer_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdfc6e-baeb-4695-b1af-84132261b82a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4732a-7080-4106-a81c-faf72c5e7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_dataloader = DataLoader(self.train_data, batch_size=6, collate_fn=data_collator, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc481ef9-e0cd-4b25-a2c4-d8ee2bd22cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def data_collator(features):\n",
    "    # split inputs and labels since they have to be of different lengths and need\n",
    "    # different padding methods\n",
    "    words = [torch.tensor(word) for word, _ in batch]\n",
    "    src = pad_sequence(words, batch_first=True, padding_value=0)\n",
    "    input_features = [feature[0] for feature in features]\n",
    "    label_features = [feature[2] for feature in features]\n",
    "\n",
    "    batch = self.processor.pad(\n",
    "        input_features,\n",
    "        padding=self.padding,\n",
    "        max_length=self.max_length,\n",
    "        pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    with self.processor.as_target_processor():\n",
    "        labels_batch = self.processor.pad(\n",
    "            label_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length_labels,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    # replace padding with -100 to ignore loss correctly\n",
    "    labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47a200-b879-4493-95b7-2a9031003278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
