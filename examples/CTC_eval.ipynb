{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5e6211-5b97-44dd-a26b-eb5937fa5010",
   "metadata": {},
   "source": [
    "#### NOTE: Also need to identify how fairseq evaluates model by wer/cer on librispeech -> enables beam search decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf301ed8-fbb6-42e9-9582-ac8f4fa210b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_fsq_model import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02f652d-d939-4cfc-8aa3-090b64019439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to wav2vec parameters\n",
    "model = load_model('../parameters/w2v2/wav2vec_small_960h.pt')\n",
    "# model = load_model('./parameters/wav2vec2_vox_960h_new.pt')\n",
    "# model = load_model('wav2vec_big_960h.pt')\n",
    "model.eval();\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7e6837-96bd-4b36-9810-dbb021a14bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Librispeech forlder\n",
    "import torchaudio\n",
    "test_data = torchaudio.datasets.LIBRISPEECH(\"../data/\", \"test-clean\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5513a44-e591-4ba6-a745-2d00f90d91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import groupby\n",
    "\n",
    "# <s>: Beginning of sentence or CTC-blank token\n",
    "# <pad>: Pad token\n",
    "# </s>: End of sentence\n",
    "# <unk>: unkown token\n",
    "# |: delimieter between words\n",
    "\n",
    "json_dict = {\"<s>\": 0, \"<pad>\": 1, \"</s>\": 2, \"<unk>\": 3, \"|\": 4, \n",
    "             \"E\": 5, \"T\": 6, \"A\": 7, \"O\": 8, \"N\": 9, \"I\": 10, \"H\": 11,\n",
    "             \"S\": 12, \"R\": 13, \"D\": 14, \"L\": 15, \"U\": 16, \"M\": 17, \"W\": 18, \n",
    "             \"C\": 19, \"F\": 20, \"G\": 21, \"Y\": 22, \"P\": 23, \"B\": 24, \"V\": 25, \n",
    "             \"K\": 26, \"'\": 27, \"X\": 28, \"J\": 29, \"Q\": 30, \"Z\": 31}\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, json_dict):\n",
    "        self.dict = json_dict\n",
    "        self.look_up = np.asarray(list(self.dict.keys()))\n",
    "\n",
    "    def decode(self, ids):\n",
    "        converted_tokens = self.look_up[ids]\n",
    "        fused_tokens = [tok[0] for tok in groupby(converted_tokens)]\n",
    "        output = ' '.join(''.join(''.join(fused_tokens).split(\"<s>\")).split(\"|\"))\n",
    "        return output\n",
    "    \n",
    "decoder = Decoder(json_dict = json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def22855-9057-404f-b1a4-f557ef3637e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44c492c-a510-4b6b-89e2-330408f5d3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation without batch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from jiwer import wer\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd4bd797-020f-413f-a8e4-34ad9b0397e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b77cd42d0743b4b56365619967ba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.03395085209981741\n"
     ]
    }
   ],
   "source": [
    "_wer = []\n",
    "_pred = []\n",
    "_ref = []\n",
    "\n",
    "for i, data in enumerate(tqdm(test_data)):\n",
    "    # Batch = 1\n",
    "    logits = model(source=data[0].cuda(), padding_mask=None)[\"encoder_out\"].transpose(0,1)\n",
    "    predicted_ids = np.argmax(logits.cpu().detach().numpy(), axis=-1)\n",
    "    prediction = [decoder.decode(ids) for ids in predicted_ids]\n",
    "    ground_truth = [data[2]]        \n",
    "    \n",
    "    # Stack predictions and ground truth to the cache memory\n",
    "    wer_metric.add_batch(predictions=prediction, references=ground_truth)\n",
    "\n",
    "# Calculate at once (same as WER between concatenated predictions & references)\n",
    "print(f\"WER: {wer_metric.compute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdfc6e-baeb-4695-b1af-84132261b82a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47728c77-054d-4313-9249-43c031541ccf",
   "metadata": {},
   "source": [
    "## Implement batch evaluation & metric wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc481ef9-e0cd-4b25-a2c4-d8ee2bd22cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# import torch\n",
    "\n",
    "# def data_collator(features):\n",
    "#     # split inputs and labels since they have to be of different lengths and need\n",
    "#     # different padding methods\n",
    "#     input_features = [feature[0].squeeze(0) for feature in features]\n",
    "#     labels = [feature[2] for feature in features]\n",
    "\n",
    "#     src = pad_sequence(input_features, batch_first=True, padding_value=0.0)\n",
    "#     mask = torch.zeros(src.shape).masked_fill_(src==0, 1)\n",
    "\n",
    "#     return src, mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54e19e80-7dd8-41bb-a8e7-d93f94be61bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]):\n",
    "        # split inputs and labels since they have to be of different lengths\n",
    "        # and need different padding methods\n",
    "        input_features = [feature[0][0] for feature in features]\n",
    "        labels = [feature[2] for feature in features]\n",
    "        # Padding value should be not zero, unless predictions will slightly changes\n",
    "        src = pad_sequence(input_features, batch_first=True, padding_value=float(\"-inf\"))\n",
    "        mask = torch.zeros(src.shape).masked_fill_(src==float(\"-inf\"), 1)\n",
    "        \n",
    "        return {'src': src, 'mask': mask, 'labels': labels}\n",
    "    \n",
    "data_collator = DataCollatorWithPadding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63e4732a-7080-4106-a81c-faf72c5e7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, collate_fn=data_collator, num_workers=4)\n",
    "\n",
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "434bf232-be3f-4cac-bdb6-19c46808b194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f59938490144a794d242fbd00b14c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.03395085209981741\n",
      "<jiwer.transforms.Compose object at 0x7f53649715d0>\n",
      "CER: 0.009526515824246084\n"
     ]
    }
   ],
   "source": [
    "wer_ = []\n",
    "cer_ = []\n",
    "\n",
    "for i, batch in enumerate(tqdm(test_dataloader)):\n",
    "    \n",
    "    logits = model(source=batch['src'].cuda(), padding_mask=batch['mask'])[\"encoder_out\"].transpose(0,1)\n",
    "    predicted_ids = np.argmax(logits.cpu().detach().numpy(), axis=-1)\n",
    "    predictions = [decoder.decode(ids) for ids in predicted_ids]\n",
    "    \n",
    "    wer_metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "    cer_metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "\n",
    "print(f\"WER: {wer_metric.compute()}\")\n",
    "print(f\"CER: {cer_metric.compute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
