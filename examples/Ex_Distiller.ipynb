{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32077d1-8996-45cd-9da2-520335205714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from s3prl.upstream.distiller.module import SplitLinear\n",
    "from modules.ConvFeatureExtractionModel import ConvFeatureExtractionModelConfig, ConvFeatureExtractionModel\n",
    "from modules.TransformerSentenceEncoderLayer import TransformerSentenceEncoderLayerConfig, TransformerSentenceEncoderLayer\n",
    "from modules.DistilTransformerEncoder import TransformerEncoderConfig, DistilTransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d54942-d2a8-4d39-8e97-3ade65e702ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from fairseq.dataclass import ChoiceEnum, FairseqDataclass\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc5484c-d471-45b8-b2c1-9b4355b99aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DistillerConfig(FairseqDataclass):\n",
    "    \n",
    "    conv_layer_setting: ConvFeatureExtractionModelConfig = field(\n",
    "        default = ConvFeatureExtractionModelConfig(),\n",
    "        metadata = {\"help\": \"Default setting of ConvFeatureExtractionModelConfig\"}\n",
    "    )\n",
    "    # Same config as Distiller version\n",
    "    encoder_setting: TransformerEncoderConfig = field(\n",
    "        default = TransformerEncoderConfig(\n",
    "                    encoder_layers = 1,\n",
    "                  ),\n",
    "        metadata = {\"help\": \"Default setting for Distilled model of TransformerEncoderConfig\"}\n",
    "    )\n",
    "    \n",
    "    feature_grad_mult: float = field(\n",
    "        default = 1.0,\n",
    "        metadata = {\"help\": \"multiply feature extractor var grads by this\"}\n",
    "    )\n",
    "    \n",
    "    final_dim: int = field(\n",
    "        default = 768,\n",
    "        metadata = {\n",
    "            \"help\": \"project final representations and targets to this many dimensions.\"\n",
    "            \"set to encoder_embed_dim is <= 0\"\n",
    "        },\n",
    "    ) \n",
    "    \n",
    "    out_layer_type: str = field(\n",
    "        default = \"expand-last\",\n",
    "        metadata = {\"help\": \"None\"},\n",
    "    )\n",
    "        \n",
    "    out_layer_inter_dim: int = field(\n",
    "        default = -1,\n",
    "        metadata = {\"help\": \"None\"},\n",
    "    )\n",
    "\n",
    "    n_tasks: int = field(\n",
    "        default = 3,\n",
    "        metadata = {\"help\": \"# of loss function between teacher model\"},\n",
    "    )\n",
    "        \n",
    "    task_emb_type: str = field(\n",
    "        default = \"expand-last\",\n",
    "        metadata = {\"help\": \"How to define embedding for loss function\"},\n",
    "    )\n",
    "    \n",
    "    task_emb_size: int = field(\n",
    "        default = 0,\n",
    "        metadata = {\"help\": \"Dimension of corresponding task embedding\"},\n",
    "    ) \n",
    "    \n",
    "    layer_emb_size: int = field(\n",
    "        default = 0,\n",
    "        metadata = {\"help\": \"None\"},\n",
    "    )\n",
    "    \n",
    "    loss_type: str = field(\n",
    "        default = \"l1\",\n",
    "        metadata = {\"help\": \"Type of loss function for distilling\"},\n",
    "    )\n",
    "    \n",
    "    feat_pen_loss: float = field(\n",
    "        default = 0.0,\n",
    "        metadata = {\"help\": \"None\"},\n",
    "    )\n",
    "    \n",
    "    cosine_loss: float = field(\n",
    "        default = 0.0,\n",
    "        metadata = {\"help\": \"Coefficient of cosing loss\"},\n",
    "    )\n",
    "    \n",
    "    # When task_emb_type == 'expand-last' only\n",
    "    pred_layer_id: str = field(\n",
    "        default = \"[3, 7, 11]\",\n",
    "        metadata = {\"help\": \"Index layer for Prediction heads\"}\n",
    "    )\n",
    "    \n",
    "    init_teacher_conv_layers: bool = field(\n",
    "        default = False,\n",
    "        metadata = {\"help\": \"Initialize to teacher's conv layers\"}\n",
    "    )\n",
    "    \n",
    "    init_teacher_encoder_layers: bool = field(\n",
    "        default = False,\n",
    "        metadata = {\"help\": \"Initialize to teacher's encoder layers\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb6bc6a-2aa2-4cfd-9a5a-52a9566408f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: DistillerConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        # ConFeatureExtraction\n",
    "        self.conv_layers = eval(cfg.conv_layer_setting.conv_feature_layers)\n",
    "        feat_emb_dim = self.conv_layers[-1][0]\n",
    "        self.feature_extractor = ConvFeatureExtractionModel(cfg.conv_layer_setting)\n",
    "        self.feature_grad_mult = cfg.feature_grad_mult\n",
    "\n",
    "        # Distillation task\n",
    "        self.n_tasks = cfg.n_tasks\n",
    "        self.task_emb_type = cfg.task_emb_type\n",
    "        final_emb_size = cfg.encoder_setting.layer_setting.encoder_embed_dim\n",
    "        if self.task_emb_type == \"add\":\n",
    "            self.task_embedding = nn.Embedding(cfg.n_tasks, cfg.encoder_setting.layer_setting.encoder_embed_dim)\n",
    "            nn.init.normal_(self.task_embedding.weight, 0.0, 0.1)\n",
    "        elif self.task_emb_type == \"concat\":\n",
    "            assert cfg.task_emb_size > 0\n",
    "            feat_emb_dim += cfg.task_emb_size\n",
    "            self.task_embedding = nn.Embedding(cfg.n_tasks, cfg.task_emb_size)\n",
    "        elif self.task_emb_type == \"concat-last\":\n",
    "            assert cfg.task_emb_size > 0\n",
    "            self.task_embedding = nn.Embedding(cfg.n_tasks, cfg.task_emb_size)\n",
    "            final_emb_size += cfg.task_emb_size\n",
    "        elif self.task_emb_type == \"expand-last\":  ## Default\n",
    "            self.pred_layer_id = eval(cfg.pred_layer_id)\n",
    "            assert self.n_tasks == len(self.pred_layer_id)\n",
    "            print(\n",
    "                f\"[DistillerModel] - Expands the output dimension by {self.n_tasks} times\"\n",
    "            )\n",
    "            print(f\"[DistillerModel] - Pred layers: {self.pred_layer_id}\")\n",
    "        elif self.task_emb_type == \"self-hidden\":\n",
    "            self.pred_layer_id = cfg.pred_layer_id\n",
    "            assert self.n_tasks == len(self.pred_layer_id)\n",
    "            assert self.n_tasks == cfg.encoder_layers + 1\n",
    "            print(\"[DistillerModel] - Predicting with self-hidden layers\")\n",
    "            print(f\"[DistillerModel] - Pred layers: {self.pred_layer_id}\")\n",
    "        elif self.task_emb_type == \"none\":\n",
    "            print(\n",
    "                f\"[DistillerModel] - Disabled task embedding (predicts only layer {self.n_tasks})\"\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown task emb type {self.task_emb_type}\")\n",
    "\n",
    "        # After ConvFeatureExtraction\n",
    "        self.post_extract_proj = (\n",
    "            nn.Linear(feat_emb_dim, cfg.encoder_setting.layer_setting.encoder_embed_dim)\n",
    "            if feat_emb_dim != cfg.encoder_setting.layer_setting.encoder_embed_dim\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # TransformerEncoderLayer\n",
    "        self.encoder_layers = cfg.encoder_setting.encoder_layers\n",
    "        if cfg.encoder_setting.encoder_layers > 0:\n",
    "            self.encoder = DistilTransformerEncoder(cfg.encoder_setting)\n",
    "        else:\n",
    "            self.encoder = nn.GELU()\n",
    "\n",
    "        final_dim = cfg.final_dim * (\n",
    "            1 if self.task_emb_type != \"expand-last\" else self.n_tasks\n",
    "        )\n",
    "\n",
    "        inter_dim = cfg.out_layer_inter_dim\n",
    "        inter_dim = inter_dim if inter_dim > 0 else final_emb_size\n",
    "\n",
    "        print(f\"[DistillerModel] - Out layer type: {cfg.out_layer_type}\")\n",
    "        if cfg.out_layer_type == \"expand-last\":\n",
    "            assert self.task_emb_type == \"expand-last\"\n",
    "            print(f\"[DistillerModel] - Inter dim = {inter_dim}\")\n",
    "            self.output_layer = nn.Sequential(\n",
    "                nn.Linear(final_emb_size, inter_dim * self.n_tasks),\n",
    "                nn.GELU(),\n",
    "                SplitLinear(inter_dim, self.n_tasks, cfg.final_dim),\n",
    "            )\n",
    "        elif cfg.out_layer_type in {\"none\", \"self-hidden\"}:\n",
    "            self.output_layer = None\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown out layer type {cfg.out_layer_type}\")\n",
    "\n",
    "    def forward_feature(self, wave, pad_mask):\n",
    "        \"\"\"Forward feature extractor\"\"\"\n",
    "\n",
    "        if self.feature_grad_mult > 0:\n",
    "            feat = self.feature_extractor(wave)\n",
    "            if self.feature_grad_mult != 1.0:\n",
    "                feat = GradMultiply.apply(feat, self.feature_grad_mult)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                feat = self.feature_extractor(wave)\n",
    "\n",
    "        feat = feat.transpose(1, 2)  # B x T x D\n",
    "        pad_mask = self.cal_pad_mask(pad_mask, feat.shape[1])\n",
    "\n",
    "        return feat, pad_mask\n",
    "\n",
    "    def forward(self, wave, pad_mask, task_id=None, get_hidden=False, no_pred=False):\n",
    "        \"\"\"\n",
    "        Forward function\n",
    "        Input:\n",
    "            wave (FloatTensor): B x T_wave\n",
    "            pad_mask (BoolTensor): B x T_wave\n",
    "            task_id (LongTensor): N >= 1\n",
    "        \"\"\"\n",
    "\n",
    "        feat, pad_mask = self.forward_feature(wave, pad_mask)\n",
    "\n",
    "        if self.task_emb_type not in [\"none\", \"expand-last\", \"self-hidden\"]:\n",
    "            if task_id is None:\n",
    "                task_id = self.generate_task_id(feat.device)\n",
    "            elif isinstance(task_id, list):\n",
    "                task_id = torch.LongTensor(task_id).to(feat.device)\n",
    "            task_embs = self.task_embedding(task_id)\n",
    "            # N x D\n",
    "            n_sz = len(task_id)\n",
    "        else:\n",
    "            n_sz = 1\n",
    "        b_sz, t_sz, _ = feat.shape\n",
    "\n",
    "        if self.task_emb_type == \"add\":\n",
    "            # Add embs to feature\n",
    "            if self.post_extract_proj is not None:\n",
    "                feat_final = self.post_extract_proj(feat)\n",
    "            else:\n",
    "                feat_final = feat\n",
    "            feat_final = feat_final.unsqueeze(1) + task_embs.unsqueeze(0).unsqueeze(2)\n",
    "        elif self.task_emb_type == \"concat\":\n",
    "            # Concatenates embs to feature\n",
    "            feat_final = torch.cat(\n",
    "                [\n",
    "                    feat.unsqueeze(1).expand(-1, n_sz, -1, -1),\n",
    "                    task_embs.unsqueeze(0).unsqueeze(2).expand(b_sz, -1, t_sz, -1),\n",
    "                ],\n",
    "                dim=-1,\n",
    "            )\n",
    "            if self.post_extract_proj is not None:\n",
    "                feat_final = self.post_extract_proj(feat_final)\n",
    "        else:\n",
    "            if self.post_extract_proj is not None:\n",
    "                feat_final = self.post_extract_proj(feat)\n",
    "            else:\n",
    "                feat_final = feat\n",
    "            feat_final = feat_final.unsqueeze(1)\n",
    "        # feat_final: B x N x T x D or B x 1 x T x D\n",
    "\n",
    "        pad_mask = pad_mask.unsqueeze(1).expand(-1, n_sz, -1).reshape(b_sz * n_sz, t_sz)\n",
    "        # BN x T\n",
    "        feat_final = feat_final.reshape(b_sz * n_sz, t_sz, -1)\n",
    "        # BN x T x D\n",
    "\n",
    "        layer_hiddens = []\n",
    "        if self.encoder_layers > 0:\n",
    "            get_hidden_tmp = (\n",
    "                True if (self.task_emb_type == \"self-hidden\") else get_hidden\n",
    "            )\n",
    "            hidden, layer_hiddens = self.encoder(\n",
    "                feat_final, ~pad_mask.bool(), get_hidden=get_hidden_tmp\n",
    "            )\n",
    "        else:\n",
    "            hidden = self.encoder(feat_final)\n",
    "\n",
    "        if not no_pred:\n",
    "            if self.task_emb_type == \"self-hidden\":\n",
    "                pred = torch.stack([feat_final] + layer_hiddens, dim=1)\n",
    "            else:\n",
    "                pred = self.output_layer(hidden).reshape(b_sz, n_sz, t_sz, -1)\n",
    "            # B x N x T x D\n",
    "        else:\n",
    "            pred = None\n",
    "\n",
    "        if (not no_pred) and self.task_emb_type == \"expand-last\":\n",
    "            assert n_sz == 1, n_sz\n",
    "            pred = (\n",
    "                pred.squeeze(1)\n",
    "                .reshape(b_sz, t_sz, self.n_tasks, -1)\n",
    "                .permute(0, 2, 1, 3)\n",
    "            )\n",
    "            # B x N x T x D\n",
    "\n",
    "        if get_hidden:\n",
    "            return feat, feat_final, pred, pad_mask, layer_hiddens\n",
    "        else:\n",
    "            return feat, feat_final, pred, pad_mask\n",
    "\n",
    "    def cal_pad_mask(self, pad_mask, max_len):\n",
    "        \"\"\"Calculates pad mask after conv.\"\"\"\n",
    "        pad_len = (pad_mask > 0).sum(1).long()\n",
    "        for _, k_size, s_size in self.conv_layers:\n",
    "            pad_len = (pad_len - k_size) // s_size + 1\n",
    "\n",
    "        new_pad_mask = torch.ones(\n",
    "            (pad_mask.shape[0], max_len), dtype=pad_mask.dtype, device=pad_mask.device\n",
    "        )\n",
    "\n",
    "        for idx in range(pad_len.shape[0]):\n",
    "            new_pad_mask[idx, pad_len[idx] :] = 0\n",
    "\n",
    "        return new_pad_mask\n",
    "\n",
    "    def generate_task_id(self, device):\n",
    "        return torch.arange(self.n_tasks, device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27267688-f219-47c3-a0f5-023ff560166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = DistillerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "354eb97f-d4ed-414c-a67b-28e9565b40aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DistillerModel] - Expands the output dimension by 3 times\n",
      "[DistillerModel] - Pred layers: [3, 7, 11]\n",
      "[DistillerModel] - Out layer type: expand-last\n",
      "[DistillerModel] - Inter dim = 768\n"
     ]
    }
   ],
   "source": [
    "model = DistillerModel(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba6d5d4-48da-4391-a2f3-2d374ac37a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "DistillerModel                                          --                        --\n",
       "├─ConvFeatureExtractionModel: 1                         --                        --\n",
       "│    └─ModuleList: 2-1                                  --                        --\n",
       "├─DistilTransformerEncoder: 1                           --                        --\n",
       "│    └─ModuleList: 2-2                                  --                        --\n",
       "├─ConvFeatureExtractionModel: 1-1                       [1, 512, 27]              --\n",
       "│    └─ModuleList: 2-1                                  --                        --\n",
       "│    │    └─Sequential: 3-1                             [1, 512, 1799]            6,144\n",
       "│    │    └─Sequential: 3-2                             [1, 512, 899]             786,432\n",
       "│    │    └─Sequential: 3-3                             [1, 512, 449]             786,432\n",
       "│    │    └─Sequential: 3-4                             [1, 512, 224]             786,432\n",
       "│    │    └─Sequential: 3-5                             [1, 512, 111]             786,432\n",
       "│    │    └─Sequential: 3-6                             [1, 512, 55]              524,288\n",
       "│    │    └─Sequential: 3-7                             [1, 512, 27]              524,288\n",
       "├─Linear: 1-2                                           [1, 27, 768]              393,984\n",
       "├─DistilTransformerEncoder: 1-3                         [1, 27, 768]              --\n",
       "│    └─Sequential: 2-3                                  [1, 768, 27]              --\n",
       "│    │    └─Conv1d: 3-8                                 [1, 768, 28]              4,719,488\n",
       "│    │    └─SamePad: 3-9                                [1, 768, 27]              --\n",
       "│    │    └─GELU: 3-10                                  [1, 768, 27]              --\n",
       "│    └─FusedLayerNorm: 2-4                              [1, 27, 768]              1,536\n",
       "│    └─ModuleList: 2-2                                  --                        --\n",
       "│    │    └─TransformerSentenceEncoderLayer: 3-11       [27, 1, 768]              7,087,872\n",
       "├─Sequential: 1-4                                       [1, 27, 2304]             --\n",
       "│    └─Linear: 2-5                                      [1, 27, 2304]             1,771,776\n",
       "│    └─GELU: 2-6                                        [1, 27, 2304]             --\n",
       "│    └─SplitLinear: 2-7                                 [1, 27, 2304]             1,771,776\n",
       "=========================================================================================================\n",
       "Total params: 17,584,512\n",
       "Trainable params: 17,584,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.13\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 24.63\n",
       "Params size (MB): 70.34\n",
       "Estimated Total Size (MB): 95.04\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "pad_mask = np.ones((1, 9000))\n",
    "\n",
    "summary(model, ((1,9000), (1,9000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e048bc-b2b6-45a6-ad3d-6e036e791a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
