{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16227c2-8818-4d03-af56-71a0cb52f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TransformerSentenceEncoderLayer import TransformerSentenceEncoderLayer, TransformerSentenceEncoderLayerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbb436d-9eac-4eee-ac00-7035bf571663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerSentenceEncoderLayerConfig(_name=None, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_attention_heads=12, dropout=0.1, attention_dropout=0.1, activation_dropout=0.0, activation_fn='gelu', layer_norm_first=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = TransformerSentenceEncoderLayerConfig()\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d674a269-f1a9-4df4-ae92-eacea0b5722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSentenceEncoderLayer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25cbc272-b6e5-464c-aa6a-9c062990a111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerSentenceEncoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea710333-2411-4a80-bc89-df9c4d601ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TransformerSentenceEncoderLayer          --                        --\n",
       "├─MultiheadAttention: 1-1                [1, 9000, 768]            --\n",
       "├─Dropout: 1-2                           [1, 9000, 768]            --\n",
       "├─FusedLayerNorm: 1-3                    [1, 9000, 768]            1,536\n",
       "├─Linear: 1-4                            [1, 9000, 3072]           2,362,368\n",
       "├─Dropout: 1-5                           [1, 9000, 3072]           --\n",
       "├─Linear: 1-6                            [1, 9000, 768]            2,360,064\n",
       "├─Dropout: 1-7                           [1, 9000, 768]            --\n",
       "├─FusedLayerNorm: 1-8                    [1, 9000, 768]            1,536\n",
       "==========================================================================================\n",
       "Total params: 4,725,504\n",
       "Trainable params: 4,725,504\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.73\n",
       "==========================================================================================\n",
       "Input size (MB): 27.65\n",
       "Forward/backward pass size (MB): 387.07\n",
       "Params size (MB): 18.90\n",
       "Estimated Total Size (MB): 433.62\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, (1, 9000, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81fd2f3-6ef6-457f-acb7-47bcb8c4e20f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
